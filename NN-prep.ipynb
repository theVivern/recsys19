{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# if you want to use the GPU\n",
    "#device = 'gpu'\n",
    "#os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=' + device + ',floatX=float32'\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#import theano\n",
    "from theano import config\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import GRU, LSTM, CuDNNGRU, CuDNNLSTM, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "\n",
    "# %% Imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "root_dir = Path().resolve()\n",
    "sys.path.append(str(root_dir / 'src'))\n",
    "\n",
    "from recsys_common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta=get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions=get_sessions(True,.05,True,0.25)\n",
    "sessions['impressions']=sessions['impressions'].str.split('\\\\|')\n",
    "sessions['prices']=sessions['prices'].str.split('\\\\|')\n",
    "print(sessions.dtypes)\n",
    "sessions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sessions.loc[sessions.is_train==False].reset_index(drop=True)\n",
    "# train = sessions.loc[(sessions.is_train==True)]\n",
    "train = sessions.loc[(sessions.is_train==True) & (sessions.is_validation==False)].reset_index(drop=True)\n",
    "dev = sessions.loc[(sessions.is_train==True) & (sessions.is_validation==True)].reset_index(drop=True)\n",
    "\n",
    "print('test',test.shape)\n",
    "print('train',train.shape)\n",
    "print('dev',dev.shape)\n",
    "\n",
    "sessions.loc[(sessions.is_validation==True)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training set in right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train[['user_id', 'session_id', 'timestamp','step', 'action_type', 'reference', 'impressions', 'prices']]\n",
    "#train_2 = train_1.copy()\n",
    "train_1['key'] = train_1['reference']\n",
    "train_1=train_1.set_index('key')\n",
    "meta['key'] = meta['item_id'].astype(str)\n",
    "meta = meta.set_index('key')\n",
    "train_1 = train_1.join(meta, on='key')\n",
    "train_1['key1'] = (train_1['user_id'] + '_' + train_1['session_id'] + '_' + train_1['timestamp'].astype(str) + '_' + train_1['step'].astype(str))\n",
    "train_1 = train_1.set_index(['key1', 'step'])\n",
    "train_1 = train_1.drop(train_1.columns[[0, 1, 2, 3, 4, 5, 6, 7]], axis=1) \n",
    "#train_4 = train_4.set_index('session_id')\n",
    "train_1.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train_1.dropna()\n",
    "train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform into 3D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train_1.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"X_train.pickle\",\"wb\")\n",
    "pickle.dump(train1, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "\n",
    "A=[]\n",
    "keys=df['action_type']\n",
    "for i in keys:\n",
    "    if i == 'clickout item':\n",
    "        A.append(1)\n",
    "    else:\n",
    "        A.append('NaN')\n",
    "\n",
    "y_train = pd.DataFrame(A)     \n",
    "y_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = train_1.join(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = y_train1.dropna()\n",
    "y_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"y_train.pickle\",\"wb\")\n",
    "pickle.dump(y_train1, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation set in right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test[['user_id', 'session_id', 'timestamp','step', 'action_type', 'reference', 'impressions', 'prices']]\n",
    "test_1['key'] = test_1['reference']\n",
    "test_1 = test_1.set_index('key')\n",
    "meta['key'] = meta['item_id'].astype(str)\n",
    "meta = meta.set_index('key')\n",
    "test_1 = train_1.join(meta, on='key')\n",
    "test_1['key1'] = (test_1['user_id'] + '_' + test_1['session_id'] + '_' + test_1['timestamp'].astype(str) + '_' + test_1['step'].astype(str))\n",
    "test_1 = test_1.set_index(['key1', 'step'])\n",
    "test_1 = test_1.drop(test_1.columns[[0, 1, 2, 3, 4, 5, 6, 7]], axis=1) \n",
    "\n",
    "test_1.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = test_1.dropna()\n",
    "test_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform into 3D Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test_1.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set:\n",
    "\n",
    "pickle_out = open(\"X_val.pickle\",\"wb\")\n",
    "pickle.dump(test1, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test.copy()\n",
    "A=[]\n",
    "keys=df['action_type']\n",
    "for i in keys:\n",
    "    if i == 'clickout item':\n",
    "        A.append(1)\n",
    "    else:\n",
    "        A.append('NaN')\n",
    "\n",
    "y_test = pd.DataFrame(A)     \n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = test_1.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1 = y_test1.dropna()\n",
    "y_test1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"y_val.pickle\",\"wb\")\n",
    "pickle.dump(y_test1, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get metadata similarities of of each hotel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"similarities.pickle\",\"wb\")\n",
    "pickle.dump(sim, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
