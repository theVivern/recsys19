{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NewOffice3\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import time\n",
    "\n",
    "# %% Imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "root_dir = Path().resolve()\n",
    "sys.path.append(str(root_dir / 'src'))\n",
    "\n",
    "from recsys_common import *\n",
    "from recsys_naive_bayes_processing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config= {\n",
    "    'save_train_test_val': True,\n",
    "    'load_fitted_model': False,\n",
    "    \n",
    "    'use_subset': True,\n",
    "    'subset_frac': 0.05,\n",
    "    'use_validation': True,\n",
    "    'validation_frac': 0.25,\n",
    "    'reference_to_nan_frac': 1,\n",
    "    'reference_to_nan_seed': 1234,\n",
    "    \n",
    "    'session_length': 1,\n",
    "    'drop_no_references': True,\n",
    "    'train_model_on_test_data': True,\n",
    "    'add_prices': False,\n",
    "    'add_hour': False,\n",
    "    'cols_to_append': [],#['platform','city','device'],\n",
    "    'drop_action_type': True,\n",
    "    \n",
    "    'train_session_chunksize': 15000,\n",
    "    'parts_nrows_test': 10000,\n",
    "    'data_path': root_dir / 'cache'\n",
    "    }\n",
    "\n",
    "\n",
    "if not config['use_subset']:\n",
    "    config['subset_frac']=1\n",
    "\n",
    "config['le_pickle_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) + '_le.pickle')\n",
    "config['train_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_train.csv')\n",
    "config['train_last_step_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_train_last_step.csv')\n",
    "config['test_last_step_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_test_last_step.csv')\n",
    "config['test_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_test.csv')\n",
    "config['val_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_val.csv')\n",
    "config['prices_pickle_path']=config['data_path'] / 'mean_prices.pickle'\n",
    "config['model_pickle_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_model.pickle')\n",
    "config['val_long_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_val_long.csv')\n",
    "config['output_recsys_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_output_recsys.csv')\n",
    "config['output_meta_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_output_meta.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['session_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta=get_metadata()\n",
    "# meta.dtypes\n",
    "\n",
    "meta['item_id']=meta['item_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting sessions\n",
      "Filter session with no clickout\n",
      "user_id                         object\n",
      "session_id                      object\n",
      "timestamp          datetime64[ns, UTC]\n",
      "step                             int64\n",
      "action_type                     object\n",
      "reference                       object\n",
      "platform                        object\n",
      "city                            object\n",
      "device                          object\n",
      "current_filters                 object\n",
      "impressions                     object\n",
      "prices                          object\n",
      "is_validation                     bool\n",
      "is_train                          bool\n",
      "target                          object\n",
      "dtype: object\n",
      "Quick unit test\n",
      "893499\n",
      "893499\n",
      "10336\n",
      "0\n",
      "0\n",
      "19995\n",
      "10336\n",
      "59661\n",
      "0\n",
      "26345\n",
      "12856\n",
      "Train encoders and save\n",
      "['change of sort order' 'clickout item' 'filter selection'\n",
      " 'interaction item deals' 'interaction item image' 'interaction item info'\n",
      " 'interaction item rating' 'search for destination' 'search for item'\n",
      " 'search for poi']\n",
      "['AA' 'AE' 'AR' 'AT' 'AU' 'BE' 'BG' 'BR' 'CA' 'CH' 'CL' 'CN' 'CO' 'CZ'\n",
      " 'DE' 'DK' 'EC' 'ES' 'FI' 'FR' 'GR' 'HK' 'HR' 'HU' 'ID' 'IE' 'IL' 'IN'\n",
      " 'IT' 'JP' 'KR' 'MX' 'MY' 'NL' 'NO' 'NZ' 'PE' 'PH' 'PL' 'PT' 'RO' 'RS'\n",
      " 'RU' 'SE' 'SG' 'SI' 'SK' 'TH' 'TR' 'TW' 'UK' 'US' 'UY' 'VN' 'ZA']\n",
      "['A Teixeira, Spain' 'Aachen, Germany' 'Aadorf, Switzerland' ...\n",
      " 'Żarki, Poland' 'Žabljak, Montenegro' 'Žilina, Slovakia']\n",
      "['desktop' 'mobile' 'tablet']\n",
      "Get Splits\n",
      "train (537963, 10)\n",
      "test (200069, 13)\n",
      "val (155467, 13)\n",
      "train user_id                         object\n",
      "session_id                      object\n",
      "timestamp          datetime64[ns, UTC]\n",
      "step                             int64\n",
      "action_type                     object\n",
      "reference                       object\n",
      "platform                        object\n",
      "city                            object\n",
      "device                          object\n",
      "current_filters                 object\n",
      "dtype: object\n",
      "test user_id                         object\n",
      "session_id                      object\n",
      "timestamp          datetime64[ns, UTC]\n",
      "step                             int64\n",
      "action_type                     object\n",
      "reference                       object\n",
      "platform                        object\n",
      "city                            object\n",
      "device                          object\n",
      "current_filters                 object\n",
      "impressions                     object\n",
      "prices                          object\n",
      "target                          object\n",
      "dtype: object\n",
      "val user_id                         object\n",
      "session_id                      object\n",
      "timestamp          datetime64[ns, UTC]\n",
      "step                             int64\n",
      "action_type                     object\n",
      "reference                       object\n",
      "platform                        object\n",
      "city                            object\n",
      "device                          object\n",
      "current_filters                 object\n",
      "impressions                     object\n",
      "prices                          object\n",
      "target                          object\n",
      "dtype: object\n",
      "Save either test or val\n",
      "delete session, test and val\n",
      "save train\n",
      "delete train\n"
     ]
    }
   ],
   "source": [
    "if config['save_train_test_val']:\n",
    "    print('Getting sessions')\n",
    "    sessions=get_sessions(config['use_subset'],\n",
    "                          config['subset_frac'],\n",
    "                          config['use_validation'],\n",
    "                          config['validation_frac'],\n",
    "                          config['reference_to_nan_frac'],\n",
    "                          config['reference_to_nan_seed'])\n",
    "\n",
    "    print('Filter session with no clickout')\n",
    "    if (not config['use_validation']) & (not config['use_subset']):\n",
    "        print('filtering sessions with clickout')\n",
    "        sessions=filter_sessions_with_no_clicks(sessions)\n",
    "\n",
    "        \n",
    "    columns_to_encode = ['action_type','platform','city','device']\n",
    "\n",
    "    if config['add_prices']:\n",
    "        print('adding prices')\n",
    "        prices=pd.read_pickle(config['prices_pickle_path'])\n",
    "        sessions=sessions.join(prices.set_index('reference'),on='reference')\n",
    "#         sessions['city_price']=sessions['city'] + sessions['mean_prices'].astype(str)\n",
    "#         columns_to_encode=np.append(columns_to_encode,['city_price'])\n",
    "    \n",
    "    if config['add_hour']:\n",
    "        sessions['hour']=sessions.timestamp.dt.hour.astype(str)\n",
    "        sessions['city_hour']=sessions['city'] + sessions['hour']\n",
    "        sessions.drop('hour',axis=1,inplace=True)\n",
    "        columns_to_encode=np.append(columns_to_encode,['city_hour'])\n",
    "        config['cols_to_append']=np.append(config['cols_to_append'],['city_hour'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(sessions.dtypes)\n",
    "    # sessions.head()\n",
    "\n",
    "    print('Quick unit test')\n",
    "\n",
    "    print(len(sessions.index))\n",
    "    print(len(sessions.index.unique()))\n",
    "\n",
    "    if not config['use_validation']:\n",
    "        sessions['is_validation']=False\n",
    "        sessions['target']=np.NaN\n",
    "\n",
    "    print(sessions.loc[(sessions.is_train==True) & (sessions.is_validation==True),'target'].count())\n",
    "    print(sessions.loc[(sessions.is_train==True) & (sessions.is_validation==False),'target'].count())\n",
    "    print(sessions.loc[(sessions.is_train==False) & (sessions.is_validation==False),'target'].count())\n",
    "\n",
    "    print(sessions.loc[(sessions.is_validation==True) & (sessions.action_type=='clickout item'),'step'].count())\n",
    "    print(sessions.loc[(sessions.is_validation==True) & (sessions.action_type=='clickout item') & (sessions.reference.isnull()),'step'].count())\n",
    "\n",
    "    print(sessions.loc[(sessions.is_train==True) & (sessions.is_validation==False) & (sessions.action_type=='clickout item') ,'step'].count())\n",
    "    print(sessions.loc[(sessions.is_train==True) & (sessions.is_validation==False) & (sessions.action_type=='clickout item') & (sessions.reference.isnull()),'step'].count())\n",
    "\n",
    "    print(sessions.loc[(sessions.is_train==False) & (sessions.is_validation==False) & (sessions.action_type=='clickout item'),'step'].count())\n",
    "    print(sessions.loc[(sessions.is_train==False) & (sessions.is_validation==False) & (sessions.action_type=='clickout item') & (sessions.reference.isnull()),'step'].count())\n",
    "    \n",
    "    if config['use_validation']:\n",
    "        n_clickouts_test = sessions.loc[(sessions.is_validation==True) & (sessions.action_type=='clickout item') & (sessions.reference.isnull()),'step'].count()\n",
    "    else:\n",
    "        n_clickouts_test = sessions.loc[(sessions.is_train==False) & (sessions.is_validation==False) & (sessions.action_type=='clickout item') & (sessions.reference.isnull()),'step'].count()\n",
    "        \n",
    "        \n",
    "    # Get possible classes\n",
    "    # classes=list(set(train.loc[(train.action_type=='clickout item') & (train.step>1),'reference']))\n",
    "    classes=list(set(sessions.loc[(sessions.action_type=='clickout item') & ~(sessions.reference.isnull()),'reference']))\n",
    "\n",
    "    \n",
    "    print('Train encoders and save')\n",
    "    encoders = {}\n",
    "    for col in columns_to_encode:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        encoders[col]=le.fit(sessions[col])\n",
    "        print(encoders[col].classes_)\n",
    "    #     val_wide[col]=encoders[col].transform(val_wide[col])\n",
    "\n",
    "    with open(config['le_pickle_path'], 'wb') as handle:\n",
    "        pickle.dump(encoders, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # with open(config['le_pickle_path'], 'rb') as handle:\n",
    "    #     b = pickle.load(handle)\n",
    "    \n",
    "    print('Get Splits')\n",
    "\n",
    "    train = sessions.loc[(sessions.is_train==True) & (sessions.is_validation==False)] \\\n",
    "                        .drop(['impressions','prices','is_train','is_validation','target'],axis=1) \\\n",
    "                        .reset_index(drop=True)\n",
    "\n",
    "    test = sessions.loc[sessions.is_train==False] \\\n",
    "                       .drop(['is_train','is_validation'],axis=1) \\\n",
    "                       .reset_index(drop=True)\n",
    "\n",
    "    val = sessions.loc[(sessions.is_train==True) & (sessions.is_validation==True)] \\\n",
    "                       .drop(['is_train','is_validation'],axis=1) \\\n",
    "                       .reset_index(drop=True)\n",
    "\n",
    "    print('train',train.shape)\n",
    "    print('test',test.shape)\n",
    "    print('val',val.shape)\n",
    "\n",
    "    print('train',train.dtypes)\n",
    "    print('test',test.dtypes)\n",
    "    print('val',val.dtypes)\n",
    "\n",
    "\n",
    "    print('Save either test or val')\n",
    "    if config['use_validation']:\n",
    "        val.to_csv(config['val_csv_path'])\n",
    "    else:\n",
    "        test.to_csv(config['test_csv_path'])\n",
    "\n",
    "\n",
    "    print('delete session, test and val')\n",
    "    try:\n",
    "        del sessions, test, val\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        gc.collect()\n",
    "     \n",
    "    \n",
    "\n",
    "\n",
    "    print('save train')\n",
    "    train.to_csv(config['train_csv_path'])\n",
    "\n",
    "else:\n",
    "    print('loading train and encoders...')\n",
    "    \n",
    "    train=pd.read_csv(config['train_csv_path'])\n",
    "    train.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "    \n",
    "    with open(config['le_pickle_path'], 'rb') as handle:\n",
    "        encoders = pickle.load(handle)\n",
    "\n",
    "    print('done')\n",
    "    \n",
    "\n",
    "last_step_per_session=train.groupby('session_id',sort=False)['step'].max().reset_index().to_csv(config['train_last_step_csv_path'])\n",
    "\n",
    "names=train.columns\n",
    "\n",
    "\n",
    "print('delete train')\n",
    "try:\n",
    "    del train\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add lost sessions back\n",
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['drop_no_references']:\n",
    "    if config['use_validation']:\n",
    "        data=pd.read_csv(config['val_csv_path'],parse_dates=['timestamp'])\n",
    "    else:\n",
    "        data=pd.read_csv(config['test_csv_path'],parse_dates=['timestamp'])\n",
    "\n",
    "    data.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "\n",
    "    val_wide = process_test_naives_bayes(data=data, metadata=meta, encoders=encoders, config=config)\n",
    "    val_wide=val_wide.loc[val_wide.impressions!=0]\n",
    "\n",
    "    try:\n",
    "        del test\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "#     val_wide_allnull=val_wide.loc[(val_wide.iloc[:,0:(2*config['session_length']-1)].T == 0).all()].copy()\n",
    "    val_wide_allnull=val_wide.copy()\n",
    "    try:\n",
    "        del val_wide\n",
    "    except NameError:\n",
    "        pass\n",
    "    else:\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Munge into same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>step</th>\n",
       "      <th>item_recommendations</th>\n",
       "      <th>item_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00EI1R7YK601</td>\n",
       "      <td>9639ee039c1d0</td>\n",
       "      <td>1541068329</td>\n",
       "      <td>3</td>\n",
       "      <td>135917 104177 106691 1409858 4529846 3822896 3...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00GKOZLYVI9R</td>\n",
       "      <td>8e74b912cb1b4</td>\n",
       "      <td>1541065310</td>\n",
       "      <td>16</td>\n",
       "      <td>3060180 3176094 5658130 4467826 5200924 198564...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00J9RN4XAC2N</td>\n",
       "      <td>d2397c03bc9b4</td>\n",
       "      <td>1541065050</td>\n",
       "      <td>122</td>\n",
       "      <td>3134112 1104106 2714672 4073430 3827338 106274...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00M5AMMLYQG5</td>\n",
       "      <td>8fd417ebd2d5b</td>\n",
       "      <td>1541062793</td>\n",
       "      <td>1</td>\n",
       "      <td>9882016 106769 48219 147360 7333050 3533848 75...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00QD3TS82ZP1</td>\n",
       "      <td>65f6d52da6c28</td>\n",
       "      <td>1541064419</td>\n",
       "      <td>3</td>\n",
       "      <td>3538112 1518663 1749805 3537348 2230166 848674...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id     session_id   timestamp step  \\\n",
       "0  00EI1R7YK601  9639ee039c1d0  1541068329    3   \n",
       "1  00GKOZLYVI9R  8e74b912cb1b4  1541065310   16   \n",
       "2  00J9RN4XAC2N  d2397c03bc9b4  1541065050  122   \n",
       "3  00M5AMMLYQG5  8fd417ebd2d5b  1541062793    1   \n",
       "4  00QD3TS82ZP1  65f6d52da6c28  1541064419    3   \n",
       "\n",
       "                                item_recommendations  \\\n",
       "0  135917 104177 106691 1409858 4529846 3822896 3...   \n",
       "1  3060180 3176094 5658130 4467826 5200924 198564...   \n",
       "2  3134112 1104106 2714672 4073430 3827338 106274...   \n",
       "3  9882016 106769 48219 147360 7333050 3533848 75...   \n",
       "4  3538112 1518663 1749805 3537348 2230166 848674...   \n",
       "\n",
       "                                          item_probs  \n",
       "0  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "1  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "2  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "3  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "4                             0 0 0 0 0 0 0 0 0 0 0   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_ordered = ['user_id', 'session_id', 'timestamp', 'step', 'item_recommendations',  'item_probs']\n",
    "\n",
    "val_wide_allnull=val_wide_allnull[['timestamp','impressions']]\n",
    "val_wide_allnull['timestamp']=val_wide_allnull['timestamp'].astype(np.int64)//10**9\n",
    "val_wide_allnull.reset_index(inplace=True)\n",
    "val_wide_allnull[['user_id','session_id','step']]=val_wide_allnull['key'].str.split('_',expand=True)\n",
    "val_wide_allnull.drop(['key'],axis=1,inplace=True)\n",
    "val_wide_allnull['item_probs']=val_wide_allnull['impressions'].str.replace('[0-9]+\\\\||[0-9]+','0 ')\n",
    "val_wide_allnull['impressions']=val_wide_allnull['impressions'].str.replace('\\\\|',' ')\n",
    "val_wide_allnull.rename(columns={'impressions':'item_recommendations'},inplace=True)\n",
    "\n",
    "\n",
    "columns_ordered = ['user_id', 'session_id', 'timestamp', 'step', 'item_recommendations',  'item_probs']\n",
    "val_wide_allnull=val_wide_allnull.reindex(columns=columns_ordered)\n",
    "\n",
    "val_wide_allnull.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append with NB fitted test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=val_wide_allnull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.drop('item_probs',axis=1).to_csv(config['output_recsys_csv_path'],index=False)\n",
    "output.to_csv(root_dir / 'cache' / 'IMPRESS_data_005_output_meta.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10336, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_wide_allnull.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_imp_wide.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(clf.feature_log_prob_).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
