{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import time\n",
    "\n",
    "# %% Imports\n",
    "from pathlib import Path\n",
    "import sys\n",
    "root_dir = Path().resolve()\n",
    "sys.path.append(str(root_dir / 'src'))\n",
    "\n",
    "from recsys_common import *\n",
    "from recsys_naive_bayes_processing import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config= {\n",
    "    'save_train_test_val': True,\n",
    "    'load_fitted_model': False,\n",
    "    \n",
    "    'use_subset': False,\n",
    "    'subset_frac': 0.05,\n",
    "    'use_validation': False,\n",
    "    'validation_frac': 0.25,\n",
    "    'reference_to_nan_frac': 1,\n",
    "    'reference_to_nan_seed': 1234,\n",
    "    \n",
    "    'session_length': 1,\n",
    "    \n",
    "    'train_session_chunksize': 5000,\n",
    "    'parts_nrows_test': 5000,\n",
    "    'parts_path_to_data': root_dir / 'cache' / 'parts',\n",
    "    'data_path': root_dir / 'cache'\n",
    "    }\n",
    "\n",
    "\n",
    "if not config['use_subset']:\n",
    "    config['subset_frac']=1\n",
    "\n",
    "config['le_pickle_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) + '_le.pickle')\n",
    "config['train_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_train.csv')\n",
    "config['train_last_step_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_train_last_step.csv')\n",
    "config['test_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_test.csv')\n",
    "config['val_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_val.csv')\n",
    "config['model_pickle_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_model.pickle')\n",
    "config['val_long_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_val_long.csv')\n",
    "config['output_recsys_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_output_recsys.csv')\n",
    "config['output_meta_csv_path']=config['data_path'] / ('NB_data_' + str(int(100*config['subset_frac'])).zfill(3) + '_' + str(config['session_length']) +  '_output_meta.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta=get_metadata()\n",
    "# meta.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['item_id']=meta['item_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['save_train_test_val']:\n",
    "    print('Getting sessions')\n",
    "    sessions=get_sessions(config['use_subset'],\n",
    "                          config['subset_frac'],\n",
    "                          config['use_validation'],\n",
    "                          config['validation_frac'],\n",
    "                          config['reference_to_nan_frac'],\n",
    "                          config['reference_to_nan_seed'])\n",
    "\n",
    "    print('Filter session with no clickout')\n",
    "    if (not config['use_validation']) & (not config['use_subset']):\n",
    "        print('filtering sessions with clickout')\n",
    "        sessions=filter_sessions_with_no_clicks(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Split impressions and prices')\n",
    "sessions['impressions']=sessions['impressions'].str.split('\\\\|')\n",
    "\n",
    "sessions['prices']=sessions['prices'].str.split('\\\\|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sessions.dtypes)\n",
    "# sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_encode = ['action_type','platform','city','device']\n",
    "\n",
    "encoders = {}\n",
    "for col in columns_to_encode:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    encoders[col]=le.fit(sessions[col])\n",
    "    print(encoders[col].classes_)\n",
    "#     val_wide[col]=encoders[col].transform(val_wide[col])\n",
    "\n",
    "with open(config['le_pickle_path'], 'wb') as handle:\n",
    "    pickle.dump(encoders, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open(config['le_pickle_path'], 'rb') as handle:\n",
    "#     b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded_prices(sessions, n_splits: int):\n",
    "    sessions_with_impressions=sessions.loc[~(sessions.impressions.isnull())].copy()\n",
    "    sessions_with_impressions['key'] = (sessions_with_impressions['user_id'] + '_' + sessions_with_impressions['session_id'] + '_' + sessions_with_impressions['step'].astype(str))\n",
    "    sessions_with_impressions=sessions_with_impressions[['key','impressions','prices']].copy()\n",
    "    \n",
    "    sessions_imp_long=sessions_with_impressions.impressions.apply(pd.Series) \\\n",
    "    .merge(sessions_with_impressions, right_index = True, left_index = True) \\\n",
    "    .drop(['impressions','prices'],axis=1) \\\n",
    "    .melt(id_vars = ['key'], value_name='impressions') \\\n",
    "    .dropna() \\\n",
    "    .sort_values(['key','variable']) \\\n",
    "    .copy()\n",
    "\n",
    "    sessions_price_long=sessions_with_impressions.prices.apply(pd.Series) \\\n",
    "    .merge(sessions_with_impressions, right_index = True, left_index = True) \\\n",
    "    .drop(['impressions','prices'],axis=1) \\\n",
    "    .melt(id_vars = ['key'], value_name='prices') \\\n",
    "    .dropna() \\\n",
    "    .sort_values(['key','variable']) \\\n",
    "    .copy()\n",
    "    \n",
    "    sessions_imp_price_long=sessions_imp_long.merge(sessions_price_long, left_on=['key','variable'], right_on=['key','variable'])\n",
    "    \n",
    "    stats=sessions_imp_price_long['prices'].astype(int).describe(percentiles=np.linspace(0,1,n_splits))\n",
    "\n",
    "    sessions_imp_price_long['prices']=pd.cut(sessions_imp_price_long['prices'].astype(int),bins=np.append(0.0,stats[4:(n_splits+5)]),labels=np.linspace(0,n_splits,n_splits+1))\n",
    "    \n",
    "    return sessions_imp_price_long.drop(['variable'],axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices=get_encoded_prices(sessions,n_splits=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.prices.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.to_pickle(root_dir / 'cache' / 'prices.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
