{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import time\n",
    "\n",
    "# %% Imports\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "import sys\n",
    "root_dir = Path().resolve()\n",
    "sys.path.append(str(root_dir / 'src'))\n",
    "\n",
    "from recsys_common import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "config= {\n",
    "    'use_subset': True,\n",
    "    'subset_frac': 0.05,\n",
    "    'use_validation': True,\n",
    "    'validation_frac': 0.25,\n",
    "    'reference_to_nan_frac': 1,\n",
    "    'reference_to_nan_seed': 1234,\n",
    "    \n",
    "    'data_path': root_dir / 'cache',\n",
    "    \n",
    "    'csvs_path': root_dir / 'outputs',\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_target(config: dict):\n",
    "    \n",
    "    print('Getting sessions')\n",
    "    \n",
    "    sessions=get_sessions(config['use_subset'],\n",
    "                          config['subset_frac'],\n",
    "                          config['use_validation'],\n",
    "                          config['validation_frac'],\n",
    "                          config['reference_to_nan_frac'],\n",
    "                          config['reference_to_nan_seed'])\n",
    "    \n",
    "    val = sessions.loc[(sessions.is_train==True) & (sessions.is_validation==True)] \\\n",
    "                   .drop(['is_train','is_validation'],axis=1) \\\n",
    "                   .reset_index(drop=True)\n",
    "\n",
    "    target = val.loc[(val.action_type=='clickout item') & (val.reference.isnull()),['user_id','session_id','timestamp','step','target']].copy()\n",
    "    \n",
    "    target['timestamp']=target['timestamp'].astype(np.int64)//10**9\n",
    "    \n",
    "    print('num_sessions_target: ', target.shape[0])\n",
    "    \n",
    "\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "\n",
    "def get_long_format(df: pd.DataFrame):\n",
    "    \n",
    "    df['item_recommendations']=df['item_recommendations'].str.split(' ')\n",
    "    df['item_probs']=df['item_probs'].str.split(' ')\n",
    "    \n",
    "    df_imp_long=df.item_recommendations.apply(pd.Series) \\\n",
    "        .merge(df, right_index = True, left_index = True) \\\n",
    "        .drop(['item_recommendations','item_probs'], axis = 1)  \\\n",
    "        .melt(id_vars=['user_id', 'session_id', 'timestamp', 'step'], \\\n",
    "              value_name = \"item_recommendations\", \\\n",
    "              var_name = \"rank\" ) \\\n",
    "        .dropna() \\\n",
    "        .sort_values(['user_id', 'session_id', 'timestamp', 'step','rank']) \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .copy()\n",
    "    \n",
    "    df_probs_long=df.item_probs.apply(pd.Series) \\\n",
    "        .merge(df, right_index = True, left_index = True) \\\n",
    "        .drop(['item_recommendations','item_probs'], axis = 1)  \\\n",
    "        .melt(id_vars=['user_id', 'session_id', 'timestamp', 'step'], \\\n",
    "              value_name = \"item_probs\", \\\n",
    "              var_name = \"rank\" ) \\\n",
    "        .dropna() \\\n",
    "        .sort_values(['user_id', 'session_id', 'timestamp', 'step','rank']) \\\n",
    "        .reset_index(drop=True) \\\n",
    "        .copy()\n",
    "    \n",
    "    df_long = df_imp_long.merge(df_probs_long,on=['user_id', 'session_id', 'timestamp', 'step','rank'])\n",
    "    df_long['rank'] = df_long['rank'] + 1\n",
    "    df_long['item_probs'] = df_long['item_probs'].astype(float)\n",
    "    \n",
    "    sum_probs=df_long.groupby(['user_id', 'session_id', 'timestamp', 'step']).item_probs.sum()\n",
    "    df_long=df_long.join(sum_probs,on=['user_id', 'session_id', 'timestamp', 'step'],rsuffix='_sum')\n",
    "    df_long['item_probs'] = df_long['item_probs']/df_long['item_probs_sum']\n",
    "    \n",
    "\n",
    "    \n",
    "    return df_long\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_MRR_stats(long: pd.DataFrame, target: pd.DataFrame):\n",
    "#     long = get_long_format(df=frame.copy())\n",
    "    \n",
    "    # re rank and calc reciprocal rank\n",
    "    long.sort_values(['user_id', 'session_id', 'timestamp', 'step','item_probs','rank'],\\\n",
    "                 ascending=[True,True,True,True,False,True],inplace=True)\n",
    "\n",
    "    long['rank2'] = 1\n",
    "    long['rank2'] = long.groupby(['user_id', 'session_id', 'timestamp', 'step'])['rank2'].cumsum()\n",
    "\n",
    "    long['RR']=1/long['rank2']\n",
    "    \n",
    "    # calc MRR\n",
    "    long=long.merge(target,on=['user_id', 'session_id', 'timestamp', 'step'])\n",
    "    \n",
    "    num_null_target = sum(long.target.isnull())\n",
    "\n",
    "    MRR = long.loc[long.item_recommendations==long.target,'RR'].mean()\n",
    "    \n",
    "    num_sessions = long.loc[long.item_recommendations==long.target,'RR'].shape[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    return MRR, num_sessions, num_null_target\n",
    "\n",
    "\n",
    "\n",
    "def main(config: dict):\n",
    "    pth = config['csvs_path']\n",
    "    \n",
    "    target = get_validation_target(config)\n",
    "    \n",
    "    MRR_stats = []\n",
    "    merged = pd.DataFrame\n",
    "\n",
    "    for ii, fpath in enumerate(pth.glob('*.csv')):\n",
    "        \n",
    "        print('Reading ', fpath.name)\n",
    "        \n",
    "        frame = get_long_format(df=pd.read_csv(fpath))\n",
    "        \n",
    "        MRR, num_sessions, num_null_target = \\\n",
    "            evaluate_MRR_stats(long=frame, target=target)\n",
    "        \n",
    "        print('MRR: ', MRR)\n",
    "        \n",
    "        MRR_stats.append([fpath.name, MRR, num_sessions, num_null_target])\n",
    "    \n",
    "        \n",
    "        frame.drop('rank',axis=1,inplace=True)\n",
    "        if ii == 0:\n",
    "            merged = frame\n",
    "        else:\n",
    "            if merged.shape[0]>frame.shape[0]:\n",
    "                merged = merged.merge(frame,on=['user_id', 'session_id', 'timestamp', 'step','item_recommendations'],how='left')\n",
    "            else:\n",
    "                merged = frame.merge(merged,on=['user_id', 'session_id', 'timestamp', 'step','item_recommendations'],how='left')\n",
    "                \n",
    "            merged.fillna(0,inplace=True)\n",
    "            merged['item_probs']=merged['item_probs_x']+merged['item_probs_y']\n",
    "            merged.drop(['item_probs_x','item_probs_y'],axis=1,inplace=True)\n",
    "            \n",
    "    merged['rank'] = 1\n",
    "    merged['rank'] = merged.groupby(['user_id', 'session_id', 'timestamp', 'step'])['rank'].cumsum()\n",
    "    \n",
    "    MRR, num_sessions, num_null_target = \\\n",
    "    evaluate_MRR_stats(long=merged, target=target)\n",
    "\n",
    "    print('Merged MRR: ', MRR)\n",
    "    \n",
    "    MRR_stats.append(['merged', MRR, num_sessions, num_null_target])\n",
    "            \n",
    "        \n",
    "                \n",
    "    \n",
    "    return merged, MRR_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting sessions\n",
      "num_sessions_target:  10336\n",
      "Reading  Impress_data_sub_005_nvars_2_output_meta.csv\n",
      "MRR:  0.5183518724167401\n",
      "Reading  NB_data_sub_005_sl_1_val_1_output_meta_2nd_filter_0.01.csv\n",
      "MRR:  0.5904056081561067\n",
      "Merged MRR:  0.5315256255393853\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>MRR</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>num_null_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Impress_data_sub_005_nvars_2_output_meta.csv</td>\n",
       "      <td>0.518352</td>\n",
       "      <td>10331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB_data_sub_005_sl_1_val_1_output_meta_2nd_fil...</td>\n",
       "      <td>0.590406</td>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merged</td>\n",
       "      <td>0.531526</td>\n",
       "      <td>10331</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file       MRR  num_sessions  \\\n",
       "0       Impress_data_sub_005_nvars_2_output_meta.csv  0.518352         10331   \n",
       "1  NB_data_sub_005_sl_1_val_1_output_meta_2nd_fil...  0.590406          1447   \n",
       "2                                             merged  0.531526         10331   \n",
       "\n",
       "   num_null_target  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged, MRR_stats=main(config)\n",
    "\n",
    "MRR_stats\n",
    "pd.DataFrame(MRR_stats,columns=['file','MRR','num_sessions','num_null_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
